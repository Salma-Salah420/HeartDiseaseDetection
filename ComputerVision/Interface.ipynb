{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41134,
     "status": "ok",
     "timestamp": 1764223990498,
     "user": {
      "displayName": "Fatema Taher Okasha",
      "userId": "09483618083073906609"
     },
     "user_tz": -120
    },
    "id": "Ma0YlRPNGw7j",
    "outputId": "b1f50afa-f8cb-41cb-b1de-d2cc6edb2048"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1064,
     "status": "ok",
     "timestamp": 1764223991566,
     "user": {
      "displayName": "Fatema Taher Okasha",
      "userId": "09483618083073906609"
     },
     "user_tz": -120
    },
    "id": "VFEfEumxGwvh"
   },
   "outputs": [],
   "source": [
    "!cp \"/content/drive/MyDrive/ECHO_NET_DYNAMIC/checkpoints/best_ef_model.pth\" \"/content/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19317,
     "status": "ok",
     "timestamp": 1764224010885,
     "user": {
      "displayName": "Fatema Taher Okasha",
      "userId": "09483618083073906609"
     },
     "user_tz": -120
    },
    "id": "8Z9KCbvtPF1z",
    "outputId": "9b2a3582-b6f1-4da3-81a5-d52a7d11198c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EFNet(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv3d(3, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (5): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (9): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): AdaptiveAvgPool3d(output_size=(1, 4, 4))\n",
       "  )\n",
       "  (lstm): LSTM(1024, 128, num_layers=2, batch_first=True)\n",
       "  (regressor): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class EFNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv3d(3, 16, kernel_size=(3,3,3), padding=1),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d((1,2,2)),\n",
    "            nn.Conv3d(16, 32, kernel_size=(3,3,3), padding=1),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d((2,2,2)),\n",
    "            nn.Conv3d(32, 64, kernel_size=(3,3,3), padding=1),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool3d((1, 4, 4))\n",
    "        )\n",
    "        self.lstm = nn.LSTM(input_size=64*4*4, hidden_size=128, num_layers=2, batch_first=True)\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        cnn_out = self.cnn(x)\n",
    "        cnn_out = cnn_out.permute(0, 2, 1, 3, 4)\n",
    "        cnn_out = cnn_out.reshape(batch_size, -1, 64*4*4)\n",
    "        lstm_out, _ = self.lstm(cnn_out)\n",
    "        last_frame_out = lstm_out[:, -1, :]\n",
    "        ef_pred = self.regressor(last_frame_out)\n",
    "        return ef_pred.squeeze()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = EFNet().to(device)\n",
    "model.load_state_dict(torch.load('/content/best_ef_model.pth', map_location=device))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 687
    },
    "executionInfo": {
     "elapsed": 3583,
     "status": "ok",
     "timestamp": 1764224014427,
     "user": {
      "displayName": "Fatema Taher Okasha",
      "userId": "09483618083073906609"
     },
     "user_tz": -120
    },
    "id": "AqsO5I0CGOU6",
    "outputId": "6f5af822-0a82-4acb-a372-d75145ba2b4c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-251174568.py:249: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
      "  with gr.Blocks(title=\"EF Prediction (Deep Learning Model)\", theme=gr.themes.Soft()) as iface:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://ba97a0998234105cc2.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://ba97a0998234105cc2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "os.makedirs(\"ef_results\", exist_ok=True)\n",
    "\n",
    "prediction_history = []\n",
    "\n",
    "\n",
    "def predict_ef(video_file, save_result=True):\n",
    "    try:\n",
    "        if video_file is None:\n",
    "            return \"<span style='color:red;font-weight:bold;'>Error: Please upload a video file.</span>\", None, None, None\n",
    "\n",
    "        video_path = video_file.name\n",
    "\n",
    "        if not str(video_path).lower().endswith((\".mp4\", \".avi\", \".mov\", \".mkv\")):\n",
    "            return \"<span style='color:red;font-weight:bold;'>Error: Unsupported video format.</span>\", None, None, None\n",
    "\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frames = []\n",
    "\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        duration = total_frames / fps if fps > 0 else 0\n",
    "\n",
    "        if total_frames == 0:\n",
    "            return \"<span style='color:red;font-weight:bold;'>Error: Cannot read video.</span>\", None, None, None\n",
    "\n",
    "        indices = np.linspace(0, total_frames - 1, 20, dtype=int)\n",
    "        extracted_frames = []\n",
    "\n",
    "        for i in indices:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                frame = np.zeros((112, 112, 3), dtype=np.uint8)\n",
    "            frame = cv2.resize(frame, (112, 112))\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(frame)\n",
    "\n",
    "            if i in [indices[0], indices[len(indices)//2], indices[-1]]:\n",
    "                extracted_frames.append((i, frame))\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        video_tensor = torch.FloatTensor(\n",
    "            np.stack(frames).transpose(3, 0, 1, 2) / 255.0\n",
    "        ).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            ef = model(video_tensor).item()\n",
    "            ef = round(ef, 2)\n",
    "\n",
    "        if ef >= 55:\n",
    "            color = \"#16a34a\"   # Green\n",
    "            status = \"Normal EF\"\n",
    "            gradient = \"linear-gradient(135deg, #4ade80, #16a34a)\"\n",
    "            status_color = \"green\"\n",
    "        elif ef >= 40:\n",
    "            color = \"#f97316\"   # Orange\n",
    "            status = \"Mildly Reduced EF\"\n",
    "            gradient = \"linear-gradient(135deg, #fb923c, #f97316)\"\n",
    "            status_color = \"orange\"\n",
    "        else:\n",
    "            color = \"#dc2626\"   # Red\n",
    "            status = \"Severely Reduced EF\"\n",
    "            gradient = \"linear-gradient(135deg, #f87171, #dc2626)\"\n",
    "            status_color = \"red\"\n",
    "\n",
    "        html_output = f\"\"\"\n",
    "        <div style=\"\n",
    "            background: {gradient};\n",
    "            padding: 25px;\n",
    "            border-radius: 18px;\n",
    "            color: white;\n",
    "            font-family: Arial, sans-serif;\n",
    "            width: 85%;\n",
    "            margin: auto;\n",
    "            box-shadow: 0 4px 15px rgba(0,0,0,0.2);\n",
    "        \">\n",
    "            <h2 style=\"margin: 0; font-size: 32px; text-align:center;\">EF Prediction</h2>\n",
    "            <p style=\"font-size: 50px; font-weight:bold; text-align:center; margin: 10px 0;\">\n",
    "                {ef}%\n",
    "            </p>\n",
    "            <p style=\"text-align:center; font-size: 20px; opacity: 0.9;\">\n",
    "                Status: <b>{status}</b>\n",
    "            </p>\n",
    "            <div style=\"display: flex; justify-content: space-between; margin-top: 15px;\">\n",
    "                <div style=\"text-align: center;\">\n",
    "                    <p style=\"font-size: 14px; margin: 0;\">Video Duration</p>\n",
    "                    <p style=\"font-size: 16px; font-weight: bold;\">{duration:.2f} sec</p>\n",
    "                </div>\n",
    "                <div style=\"text-align: center;\">\n",
    "                    <p style=\"font-size: 14px; margin: 0;\">Total Frames</p>\n",
    "                    <p style=\"font-size: 16px; font-weight: bold;\">{total_frames}</p>\n",
    "                </div>\n",
    "                <div style=\"text-align: center;\">\n",
    "                    <p style=\"font-size: 14px; margin: 0;\">FPS</p>\n",
    "                    <p style=\"font-size: 16px; font-weight: bold;\">{fps:.2f}</p>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "\n",
    "        fig_ef = go.Figure(go.Indicator(\n",
    "            mode = \"gauge+number+delta\",\n",
    "            value = ef,\n",
    "            domain = {'x': [0, 1], 'y': [0, 1]},\n",
    "            title = {'text': \"Ejection Fraction (%)\"},\n",
    "            delta = {'reference': 55},\n",
    "            gauge = {\n",
    "                'axis': {'range': [None, 100]},\n",
    "                'bar': {'color': color},\n",
    "                'steps': [\n",
    "                    {'range': [0, 40], 'color': \"lightgray\"},\n",
    "                    {'range': [40, 55], 'color': \"gray\"},\n",
    "                    {'range': [55, 100], 'color': \"lightgray\"}\n",
    "                ],\n",
    "                'threshold': {\n",
    "                    'line': {'color': \"red\", 'width': 4},\n",
    "                    'thickness': 0.75,\n",
    "                    'value': 55\n",
    "                }\n",
    "            }\n",
    "        ))\n",
    "        fig_ef.update_layout(height=300, font={'color': \"darkblue\", 'family': \"Arial\"})\n",
    "\n",
    "        fig_frames = px.imshow(\n",
    "            np.array([frame for _, frame in extracted_frames]),\n",
    "            facet_col=0,\n",
    "            binary_string=False,\n",
    "            labels={'facet_col': 'Sample Frames'},\n",
    "            title='Sample Frames from Video'\n",
    "        )\n",
    "        fig_frames.update_xaxes(showticklabels=False)\n",
    "        fig_frames.update_yaxes(showticklabels=False)\n",
    "        for i in range(len(extracted_frames)):\n",
    "            fig_frames.layout.annotations[i]['text'] = f\"Frame {extracted_frames[i][0]}\"\n",
    "\n",
    "        if save_result:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            result = {\n",
    "                \"timestamp\": timestamp,\n",
    "                \"ef\": ef,\n",
    "                \"status\": status,\n",
    "                \"video_path\": video_path,\n",
    "                \"duration\": duration,\n",
    "                \"total_frames\": total_frames,\n",
    "                \"fps\": fps\n",
    "            }\n",
    "\n",
    "            prediction_history.append(result)\n",
    "\n",
    "            with open(f\"ef_results/result_{timestamp}.json\", \"w\") as f:\n",
    "                json.dump(result, f)\n",
    "\n",
    "        if prediction_history:\n",
    "            df = pd.DataFrame(prediction_history[-5:])  # Show last 5 predictions\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'], format='%Y%m%d_%H%M%S')\n",
    "            df = df.sort_values('timestamp', ascending=False)\n",
    "            df['timestamp'] = df['timestamp'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "            df = df[['timestamp', 'ef', 'status']]\n",
    "            df.columns = ['Timestamp', 'EF (%)', 'Status']\n",
    "\n",
    "            def highlight_status(val):\n",
    "                if val == 'Normal EF':\n",
    "                    return 'background-color: #d4edda'\n",
    "                elif val == 'Mildly Reduced EF':\n",
    "                    return 'background-color: #fff3cd'\n",
    "                else:\n",
    "                    return 'background-color: #f8d7da'\n",
    "\n",
    "            styled_df = df.style.applymap(highlight_status, subset=['Status'])\n",
    "            history_table = styled_df.to_html()\n",
    "        else:\n",
    "            history_table = \"<p>No prediction history available</p>\"\n",
    "\n",
    "        return html_output, fig_ef, fig_frames, history_table\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = f\"<span style='color:red;font-weight:bold;'>Error: {str(e)}</span>\"\n",
    "        print(f\"Full error details: {e}\")  \n",
    "        return error_msg, None, None, None\n",
    "\n",
    "def clear_history():\n",
    "    global prediction_history\n",
    "    prediction_history = []\n",
    "    return \"<p>History cleared</p>\"\n",
    "\n",
    "def download_history():\n",
    "    if not prediction_history:\n",
    "        return None\n",
    "\n",
    "    df = pd.DataFrame(prediction_history)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], format='%Y%m%d_%H%M%S')\n",
    "    df = df.sort_values('timestamp', ascending=False)\n",
    "    df['timestamp'] = df['timestamp'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    csv_path = f\"ef_results/history_{timestamp}.csv\"\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "    return csv_path\n",
    "\n",
    "#  Web Interface\n",
    "with gr.Blocks(title=\"EF Prediction (Deep Learning Model)\", theme=gr.themes.Soft()) as iface:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # Ejection Fraction (EF) Prediction System\n",
    "\n",
    "    Upload an echocardiography video and the deep learning model will predict the **Ejection Fraction (EF)** with color-coded severity levels.\n",
    "\n",
    "    ## How to use:\n",
    "    1. Upload a video file (MP4, AVI, MOV, MKV)\n",
    "    2. Click \"Predict EF\" to analyze the video\n",
    "    3. View the results and sample frames\n",
    "    4. Check the prediction history below\n",
    "    \"\"\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            video_input = gr.File(file_types=[\"video\"], label=\"Upload Echocardiography Video\")\n",
    "            predict_btn = gr.Button(\"Predict EF\", variant=\"primary\")\n",
    "\n",
    "            with gr.Row():\n",
    "                clear_btn = gr.Button(\"Clear History\")\n",
    "                download_btn = gr.Button(\"Download History\")\n",
    "\n",
    "            gr.Markdown(\"\"\"\n",
    "            ### About EF Values:\n",
    "            - **Normal EF**: â‰¥55% (Green)\n",
    "            - **Mildly Reduced EF**: 40-54% (Orange)\n",
    "            - **Severely Reduced EF**: <40% (Red)\n",
    "            \"\"\")\n",
    "\n",
    "            gr.Markdown(\"\"\"\n",
    "            ### Model Information:\n",
    "            - Architecture: 3D CNN\n",
    "            - Input: 20 frames (112x112 RGB)\n",
    "            - Training Dataset: EchoNet-Dynamic\n",
    "            \"\"\")\n",
    "\n",
    "            download_output = gr.File(label=\"Download History CSV\", visible=False)\n",
    "\n",
    "        with gr.Column(scale=2):\n",
    "            html_output = gr.HTML(label=\"Prediction Result\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            fig_ef = gr.Plot(label=\"EF Value Visualization\")\n",
    "\n",
    "        with gr.Column():\n",
    "            fig_frames = gr.Plot(label=\"Sample Frames from Video\")\n",
    "\n",
    "    with gr.Row():\n",
    "        history_table = gr.HTML(label=\"Prediction History\")\n",
    "\n",
    "    predict_btn.click(\n",
    "        fn=predict_ef,\n",
    "        inputs=[video_input],\n",
    "        outputs=[html_output, fig_ef, fig_frames, history_table]\n",
    "    )\n",
    "\n",
    "    clear_btn.click(\n",
    "        fn=clear_history,\n",
    "        outputs=[history_table]\n",
    "    )\n",
    "\n",
    "    download_btn.click(\n",
    "        fn=download_history,\n",
    "        outputs=[download_output]\n",
    "    ).then(\n",
    "        lambda: gr.File(visible=True),\n",
    "        outputs=[download_output]\n",
    "    )\n",
    "\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "118gfynupR0R"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPK65u9byySIZcUOPtgh0wb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
